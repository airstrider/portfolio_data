{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Tensorflow time series deep learning model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project will build a neural network model to predict sunspot activity.\n",
    "The goal is to:\n",
    "- Build a neural network model with a provided dataset using Tensorflow packages.\n",
    "- Make predictions of sunspot activity using the model.\n",
    "\n",
    "Before building and executing the neural network model, basic EDA, data cleaning, and other manipulations will be conducted to prepare the data for modeling if necessary.\n",
    "\n",
    "Modeling follows the steps:\n",
    "1. Importing packages and loading data\n",
    "2. Exploring the data and completing the cleaning process (optional)\n",
    "3. Building a neural network\n",
    "4. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing packages and loading data\n",
    "\n",
    "#### 1.1. Import packages\n",
    "\n",
    "Import relevant Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard operational packages\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "# Data preparation packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Modeling and evaluation packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Load the dataset\n",
    "\n",
    "Download the `Sunspot.csv` dataset from the tensorflow data storage\n",
    "\n",
    "Save it as `sunspots.csv` into a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/sunspots.csv', <http.client.HTTPMessage at 0x7fb04a175d10>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n",
    "urllib.request.urlretrieve(url, '../data/sunspots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Monthly Mean Total Sunspot Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749-01-31</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749-02-28</td>\n",
       "      <td>104.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749-03-31</td>\n",
       "      <td>116.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749-04-30</td>\n",
       "      <td>92.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749-05-31</td>\n",
       "      <td>141.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3235 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Monthly Mean Total Sunspot Number\n",
       "0     1749-01-31                               96.7\n",
       "1     1749-02-28                              104.3\n",
       "2     1749-03-31                              116.7\n",
       "3     1749-04-30                               92.8\n",
       "4     1749-05-31                              141.7\n",
       "...          ...                                ...\n",
       "3230  2018-03-31                                2.5\n",
       "3231  2018-04-30                                8.9\n",
       "3232  2018-05-31                               13.2\n",
       "3233  2018-06-30                               15.9\n",
       "3234  2018-07-31                                1.6\n",
       "\n",
       "[3235 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sunspots.csv').drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Exploring the data and completing the cleaning process\n",
    "\n",
    "#### 2.1. Prepare the data\n",
    "\n",
    "After downloading the dataset, prepare the data to be suitable for a neural network model.\n",
    "- Exploring the data\n",
    "- Checking for missing values\n",
    "- Encoding the data\n",
    "- Split the `original` dataset into `train` and `test` dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Explore the the data\n",
    "\n",
    "Use functions to take a look at the data\n",
    "- `shape`\n",
    "- `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3235, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3235 entries, 0 to 3234\n",
      "Data columns (total 2 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Date                               3235 non-null   object \n",
      " 1   Monthly Mean Total Sunspot Number  3235 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 50.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Check for missing values\n",
    "\n",
    "Check for missing values in the rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                 0\n",
       "Monthly Mean Total Sunspot Number    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building a neural network model\n",
    "\n",
    "#### 3.1. Create the training and testing data\n",
    "\n",
    "From the dataframe review, this project needs the `Monthly Mean Total Sunspot Number` field.\n",
    "1. Extract only the field from `df`.\n",
    "2. Convert the dataframe object into array object.\n",
    "3. Normalize the data with a scaler.\n",
    "4. Create a `training` set with between `1st` and `3000th` rows of the data.\n",
    "5. Create a `validation` set with the remaining rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monthly Mean Total Sunspot Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3235 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Monthly Mean Total Sunspot Number\n",
       "0                                  96.7\n",
       "1                                 104.3\n",
       "2                                 116.7\n",
       "3                                  92.8\n",
       "4                                 141.7\n",
       "...                                 ...\n",
       "3230                                2.5\n",
       "3231                                8.9\n",
       "3232                               13.2\n",
       "3233                               15.9\n",
       "3234                                1.6\n",
       "\n",
       "[3235 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Extract only the field from `df`.\n",
    "df = df.drop(columns=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96.7],\n",
       "       [104.3],\n",
       "       [116.7],\n",
       "       ...,\n",
       "       [ 13.2],\n",
       "       [ 15.9],\n",
       "       [  1.6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Convert the dataframe object into array object.\n",
    "series = np.array(df).reshape(-1,1)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24284279],\n",
       "       [0.26192868],\n",
       "       [0.29306881],\n",
       "       ...,\n",
       "       [0.03314917],\n",
       "       [0.03992968],\n",
       "       [0.00401808]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Normalize the data with a scaler.\n",
    "scaler = MinMaxScaler()\n",
    "series = scaler.fit_transform(series)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Set a split number.\n",
    "spilt_rows = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Create a `training` set with between `1st` and `3000th` rows of the data.\n",
    "x_train = series[:spilt_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Create a `validation` set with the remaining rows. \n",
    "x_valid = series[spilt_rows:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 1), (235, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Create a neural network model\n",
    "\n",
    "1. Set parameters for data set preparation.\n",
    "2. Identify a method to prepare a train set for neural network model.\n",
    "3. Prepare a train set and valid set with the method.\n",
    "4. Set a model check point.\n",
    "5. Set an optimizer.\n",
    "6. Set a loss.\n",
    "7. Compile the model.\n",
    "8. Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Set parameters for data set preparation.\n",
    "window_size = 30\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Identify a method to prepare a train set for neural network model.\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 15:02:00.772733: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#3. Prepare a train set and valid set with the method.\n",
    "train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n",
    "valid_set = windowed_dataset(x_valid, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Create a neural network model.\n",
    "model = Sequential([\n",
    "    Conv1D(60, kernel_size=5, padding='causal', activation='relu', input_shape=[None,1]),\n",
    "    LSTM(60, return_sequences=True),\n",
    "    LSTM(60, return_sequences=True),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Set a model check point.\n",
    "checkpoint_path = '../data/temp_checkpoint.ckpt'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_mae',\n",
    "                             verbose=1,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Set an optimizer.\n",
    "optimizer = SGD(learning_rate=0.00001,\n",
    "                momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Set a loss.\n",
    "loss = Huber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Execute the neural network Model\n",
    "\n",
    "1. Compile the model.\n",
    "2. Fit the model.\n",
    "3. Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Compile the model.\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Fit the model.\n",
    "model.fit(x=train_set,\n",
    "          validation_data=(valid_set),\n",
    "          epochs=100,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0100 - mae: 0.1134\n",
      "evaluate: [0.009972674772143364, 0.11337368935346603]\n"
     ]
    }
   ],
   "source": [
    "#3. Evaluate the results.\n",
    "model.load_weights(checkpoint_path)\n",
    "print('evaluate:', model.evaluate(valid_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rkim_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
